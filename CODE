import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn import metrics
import numpy as np
import matplotlib.pyplot as plt
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
import re

train_path = "C:/CODING/WORKING/train.csv"
test_path = "C:/CODING/WORKING/test.csv"
output_path = "C:/CODING/WORKING/output.csv"

# Load the datasets
print("Loading datasets...")
train_data = pd.read_csv(train_path)
test_data = pd.read_csv(test_path)

# Check for missing values in text column and handle them
print(f"Train data shape before cleaning: {train_data.shape}")
train_data = train_data.dropna(subset=['text'])
print(f"Train data shape after cleaning: {train_data.shape}")

# Initialize the Porter Stemmer
stemmer = PorterStemmer()

# Text preprocessing function
def preprocess_text(text):
    if isinstance(text, str):
        # Remove non-alphabetic characters
        cleaned_text = re.sub('[^a-zA-Z]', ' ', text)
        # Convert to lowercase
        cleaned_text = cleaned_text.lower()
        # Split into words
        cleaned_text = cleaned_text.split()
        # Remove stopwords and stem words
        cleaned_text = [stemmer.stem(word) for word in cleaned_text if word not in stopwords.words('english')]
        # Join back into a string
        cleaned_text = ' '.join(cleaned_text)
        return cleaned_text
    else:
        return ""  # Return empty string for NaN values

# Process training data
print("Preprocessing training data...")
train_processed_texts = train_data['text'].apply(preprocess_text)

# TF-IDF Vectorization
print("Vectorizing text data...")
tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,3))
train_features = tfidf_vectorizer.fit_transform(train_processed_texts)
train_labels = train_data['label']

# Split for validation
X_train, X_val, y_train, y_val = train_test_split(train_features, train_labels, test_size=0.2, random_state=42)

# Train the classifier
print("Training model...")
classifier = MultinomialNB()
classifier.fit(X_train, y_train)

# Validate the model
val_predictions = classifier.predict(X_val)
accuracy = metrics.accuracy_score(y_val, val_predictions)
print(f"Validation accuracy: {accuracy:.4f}")

# Confusion Matrix
conf_matrix = metrics.confusion_matrix(y_val, val_predictions)
print("Confusion matrix:")
print(conf_matrix)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
class_labels = ['FAKE', 'REAL']
tick_marks = np.arange(len(class_labels))
plt.xticks(tick_marks, class_labels, rotation=45)
plt.yticks(tick_marks, class_labels)

threshold = conf_matrix.max() / 2.
for i in range(conf_matrix.shape[0]):
    for j in range(conf_matrix.shape[1]):
        plt.text(j, i, conf_matrix[i, j],
                 horizontalalignment="center",
                 color="white" if conf_matrix[i, j] > threshold else "black")

plt.tight_layout()
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.savefig('C:/CODING/WORKING/confusion_matrix.png')
plt.close()

# Now retrain on full training data
print("Retraining on full dataset...")
classifier = MultinomialNB()
classifier.fit(train_features, train_labels)

# Process test data
print("Preprocessing test data...")
test_processed_texts = test_data['text'].fillna("").apply(preprocess_text)
test_features = tfidf_vectorizer.transform(test_processed_texts)

# Predict on test data
print("Predicting on test data...")
test_predictions = classifier.predict(test_features)

# Create output file
print("Creating output file...")
output = pd.DataFrame({
    'id': test_data['id'],
    'label': test_predictions
})
output.to_csv(output_path, index=False)

print(f"Output file created at {output_path}")
